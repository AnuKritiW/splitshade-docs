import{_ as t,c as a,o as r,ae as o}from"./chunks/framework.DmqzXzOt.js";const p=JSON.parse('{"title":"What are Textures?","description":"","frontmatter":{},"headers":[],"relativePath":"textures/what-are.md","filePath":"textures/what-are.md"}'),s={name:"textures/what-are.md"};function d(i,e,l,n,u,h){return r(),a("div",null,e[0]||(e[0]=[o('<h1 id="what-are-textures" tabindex="-1">What are Textures? <a class="header-anchor" href="#what-are-textures" aria-label="Permalink to &quot;What are Textures?&quot;">​</a></h1><p>In shaders, <strong>textures</strong> are images used as data sources. They allow you to add rich detail to your visuals—like colors, patterns, noise, masks, or even entire scenes—without manually computing every pixel value.</p><h2 id="why-use-textures" tabindex="-1">Why Use Textures? <a class="header-anchor" href="#why-use-textures" aria-label="Permalink to &quot;Why Use Textures?&quot;">​</a></h2><p>Textures let you:</p><ul><li>Apply image-based detail without complex math</li><li>Reuse real-world images or hand-drawn art</li><li>Store custom data like flow maps or normal maps</li><li>Add stylization, distortion, or layering</li></ul><h2 id="types-of-texture-data" tabindex="-1">Types of Texture Data <a class="header-anchor" href="#types-of-texture-data" aria-label="Permalink to &quot;Types of Texture Data&quot;">​</a></h2><p>Textures don&#39;t always just hold color. They can represent:</p><table tabindex="0"><thead><tr><th>Type</th><th>Description</th></tr></thead><tbody><tr><td><strong>Color Map</strong></td><td>Regular image used for shading</td></tr><tr><td><strong>Mask</strong></td><td>A grayscale image for blending/mixing</td></tr><tr><td><strong>Normal Map</strong></td><td>Encodes surface bump direction</td></tr><tr><td><strong>Height Map</strong></td><td>Stores elevation or depth data</td></tr><tr><td><strong>Distortion</strong></td><td>Offsets UVs for warping effects</td></tr></tbody></table><h2 id="how-are-textures-used" tabindex="-1">How Are Textures Used? <a class="header-anchor" href="#how-are-textures-used" aria-label="Permalink to &quot;How Are Textures Used?&quot;">​</a></h2><p>In <code>WGSL</code> shaders, textures are sampled using two parts:</p><ul><li>A <code>texture_2d&lt;f32&gt;</code> – the image data</li><li>A <code>sampler</code> – the method for reading/interpolating pixels</li></ul><p>Where:</p><ul><li><code>iChannel0</code> is a <code>texture_2d&lt;f32&gt;</code></li><li><code>iChannel0Sampler</code> is a <code>sampler</code></li><li><code>uv</code> is a <code>vec2&lt;f32&gt;</code> in the range <code>[0.0, 1.0]</code></li></ul><h2 id="uv-coordinates" tabindex="-1">UV Coordinates <a class="header-anchor" href="#uv-coordinates" aria-label="Permalink to &quot;UV Coordinates&quot;">​</a></h2><p>UVs are how you look up pixels in a texture.</p><ul><li><code>(0.0, 0.0)</code> = bottom-left</li><li><code>(1.0, 1.0)</code> = top-right</li></ul><p>Values outside <code>[0.0, 1.0]</code> may repeat or clamp, depending on the sampler</p><hr><p>To learn how to assign textures in the <strong>Splitshade</strong> UI, continue to <a href="./usage.html">Texture Usage</a>.</p><p>To see how to use textures in your <code>WGSL</code> shader code, see <a href="./../uniforms/iChannel.html">iChannel0–iChannel3</a>.</p>',20)]))}const m=t(s,[["render",d]]);export{p as __pageData,m as default};
